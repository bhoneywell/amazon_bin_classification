{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Title\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of the TODO's and/or use more than one cell to complete all the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Install any packages that you might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `train_data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not acessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1228 [00:00<02:46,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 1 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [01:56<00:00, 10.54it/s]\n",
      "  0%|          | 1/2299 [00:00<04:28,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 2 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2299/2299 [03:45<00:00, 10.19it/s]\n",
      "  0%|          | 2/2666 [00:00<03:10, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 3 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2666/2666 [04:23<00:00, 10.13it/s]\n",
      "  0%|          | 2/2373 [00:00<02:36, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 4 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [03:47<00:00, 10.41it/s]\n",
      "  0%|          | 2/1875 [00:00<02:12, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 5 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [03:07<00:00,  9.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_arrange_data():\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_client.download_file('aft-vbi-pds', os.path.join('bin-images', file_name),\n",
    "                             os.path.join(directory, file_name))\n",
    "\n",
    "download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count_objects\n",
      "1           1228\n",
      "2           2299\n",
      "3           2666\n",
      "4           2373\n",
      "5           1875\n"
     ]
    }
   ],
   "source": [
    "image_dict = {1:1228,2:2299,3:2666,4:2373,5:1875}\n",
    "df = pd.DataFrame.from_dict(image_dict,orient='index')\n",
    "df = df.rename(columns={df.columns[0]: 'count_objects'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbbf58bbfd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**TODO:** Explain what dataset you are using for this project. Give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understanding of it. You can find more information about the data [here](https://registry.opendata.aws/amazon-bin-imagery/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Perform any data cleaning or data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/nd009t-capstone-starter/starter\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Code to separate the files into train, test split. The data is split 60% train, 20% test and 20% validation\n",
    "\n",
    "def split_data(data_dir, test_size=0.2):\n",
    "    # Get the filenames in the data directory\n",
    "    filenames = os.listdir(data_dir)\n",
    "    # Split the filenames into train and test sets\n",
    "    X_train, X_test = train_test_split(filenames, test_size=test_size, random_state=0)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pth = '/root/nd009t-capstone-starter/starter/train_data/'+str(i)\n",
    "    X_train, X_test = split_data(pth)\n",
    "    X_train, X_val = train_test_split(X_train, test_size=0.25, random_state=0)\n",
    "    train_pth = '/root/nd009t-capstone-starter/starter/train_input/'+str(i)\n",
    "    test_pth = '/root/nd009t-capstone-starter/starter/test_input/'+str(i)\n",
    "    val_pth = '/root/nd009t-capstone-starter/starter/val_input/'+str(i)\n",
    "    for filename in X_train: \n",
    "        src_pth = os.path.join(pth, filename)\n",
    "        dst_path = os.path.join(train_pth, filename)\n",
    "        # Check if the destination folder exists\n",
    "        if not os.path.exists(os.path.dirname(dst_path)):\n",
    "            # Create the destination folder\n",
    "            os.makedirs(os.path.dirname(dst_path))\n",
    "        # Move the file from the source to the destination\n",
    "        shutil.move(src_pth, dst_path)\n",
    "    for filename in X_test: \n",
    "        src_pth = os.path.join(pth, filename)\n",
    "        dst_path = os.path.join(test_pth, filename)\n",
    "        # Check if the destination folder exists\n",
    "        if not os.path.exists(os.path.dirname(dst_path)):\n",
    "            # Create the destination folder\n",
    "            os.makedirs(os.path.dirname(dst_path))\n",
    "        # Move the file from the source to the destination\n",
    "        shutil.move(src_pth, dst_path)\n",
    "    for filename in X_val: \n",
    "        src_pth = os.path.join(pth, filename)\n",
    "        dst_path = os.path.join(val_pth, filename)\n",
    "        # Check if the destination folder exists\n",
    "        if not os.path.exists(os.path.dirname(dst_path)):\n",
    "            # Create the destination folder\n",
    "            os.makedirs(os.path.dirname(dst_path))\n",
    "        # Move the file from the source to the destination\n",
    "        shutil.move(src_pth, dst_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-330592931683\n"
     ]
    }
   ],
   "source": [
    "#Import sagemaker details\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'capstone-project/'\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the train, test and validaton data to s3\n",
    "prefix_dict = {\n",
    "    '/root/nd009t-capstone-starter/starter/train_input/':'capstone-project/train_input/',\n",
    "    '/root/nd009t-capstone-starter/starter/test_input/':'capstone-project/test_input/',\n",
    "    '/root/nd009t-capstone-starter/starter/val_input/':'capstone-project/val_input/'}\n",
    "\n",
    "for local_dir in prefix_dict.keys(): \n",
    "    prefix = prefix_dict[local_dir]\n",
    "    # Iterate through the files in the local directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(local_dir):\n",
    "        # Iterate through the files\n",
    "        for file in files:\n",
    "            # Construct the full path to the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Construct the S3 key (i.e., the path) for the file\n",
    "            key = prefix + os.path.relpath(file_path, local_dir)\n",
    "            # Upload the file to S3\n",
    "            s3.upload_file(file_path, bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important. \n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "#TODO: Declare your HP ranges, metrics etc.\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 4,\n",
    "    \"lr\":0.01\n",
    "}\n",
    "\n",
    "objective_metric_name = \"average accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": \"accuracy\", \"Regex\": \"Testing Accuracy: (?[0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "# TODO: Create and fit an estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    entry_point=\"train.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters=hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data Directories\n",
    "input_data = 's3://sagemaker-us-east-1-330592931683/capstone-project'\n",
    "s3_output_dir = \"s3://{}/{}/{}/\".format(bucket,\"capstone-project\", \"output\")\n",
    "s3_model_dir = \"s3://{}/{}/\".format(bucket,\"capstone-project\", \"model\")\n",
    "\n",
    "os.environ['SM_CHANNEL_TRAINING'] = input_data\n",
    "os.environ['SM_MODEL_DIR'] = s3_model_dir\n",
    "os.environ['SM_OUTPUT_DATA_DIR'] = s3_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-05 20:38:28 Starting - Starting the training job...\n",
      "2023-01-05 20:38:52 Starting - Preparing the instances for trainingProfilerReport-1672951108: InProgress\n",
      "......\n",
      "2023-01-05 20:39:52 Downloading - Downloading input data...\n",
      "2023-01-05 20:40:19 Training - Downloading the training image...\n",
      "2023-01-05 20:40:53 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,109 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,112 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,120 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,122 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,305 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,319 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,329 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-05 20:40:48,338 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 32,\n",
      "        \"epochs\": 4,\n",
      "        \"lr\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-01-05-20-38-27-973\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-330592931683/pytorch-training-2023-01-05-20-38-27-973/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":32,\"epochs\":4,\"lr\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-330592931683/pytorch-training-2023-01-05-20-38-27-973/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":32,\"epochs\":4,\"lr\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-01-05-20-38-27-973\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-330592931683/pytorch-training-2023-01-05-20-38-27-973/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"32\",\"--epochs\",\"4\",\"--lr\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=4\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch_size 32 --epochs 4 --lr 0.01\u001b[0m\n",
      "\u001b[34mEpoch 0, Phase train\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:49.669 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:49.842 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:49.842 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:49.842 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:49.843 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:49.843 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:50.047 algo-1:27 INFO hook.py:591] name:fc.0.weight count_params:5120\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:50.048 algo-1:27 INFO hook.py:591] name:fc.0.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:50.048 algo-1:27 INFO hook.py:593] Total Trainable Params: 5130\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:50.048 algo-1:27 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2023-01-05 20:40:50.051 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34mImages [4000/6262 (64%)] Loss: 1.56 Accuracy: 976/4000 (24.40%)\u001b[0m\n",
      "\u001b[34mEpoch 0, Phase valid\u001b[0m\n",
      "\u001b[34mEpoch 1, Phase train\u001b[0m\n",
      "\u001b[34mImages [4000/6262 (64%)] Loss: 1.35 Accuracy: 1179/4000 (29.48%)\u001b[0m\n",
      "\u001b[34mEpoch 1, Phase valid\u001b[0m\n",
      "\u001b[34mEpoch 2, Phase train\u001b[0m\n",
      "\u001b[34mImages [4000/6262 (64%)] Loss: 1.32 Accuracy: 1296/4000 (32.40%)\u001b[0m\n",
      "\u001b[34mEpoch 2, Phase valid\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 30.66985645933014, Test set: Average loss: 1.5045211138337422\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 1.5045\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 54%|█████▍    | 24.3M/44.7M [00:00<00:00, 255MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 272MB/s]\u001b[0m\n",
      "\u001b[34m2023-01-05 20:50:54,759 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-01-05 20:50:59 Uploading - Uploading generated training model\n",
      "2023-01-05 20:51:35 Completed - Training job completed\n",
      "ProfilerReport-1672951108: NoIssuesFound\n",
      "Training seconds: 687\n",
      "Billable seconds: 687\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "estimator.fit({'train': input_data+'/train_input',       \n",
    "'test': input_data+'/test_input',      \n",
    "'val': input_data+'/val_input'},wait=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
